---
title: "R Notebook"
output: html_notebook
---

### Main algorithm

```{r}
# Helper function
dmvnorm <- function(Mu, Sigma, x) {
  # computes f(x; Mu, Sigma)
  #
  # Args: 
  #   Mu: mean 
  #   Sigma: covariance matrix
  #   x: observed data
  #
  # Returns:
  #   f(x; Mu, Sigma), density function of N(Mu, Sigma) evaled at X
  
  # d variate GMM
  d <- length(Mu)
  # compute f
  1/sqrt((2*pi)^(d)*det(Sigma))*exp(-1/2*t(x - Mu)%*%solve(Sigma)%*%(x - Mu)) 
}
```


```{r}
# EM Robust algorithm
EM_Robust <- function(X, nC, tol = 1e-10, m_iter=1e4) {
  # Estimates centers of Gaussian Mixture models without manual initialization:
  #
  # Args:
  #   X: Data, d by n matrix, n obs, d variates
  #   tol: tolerance for convergence
  #   m_iter: max iterations
  #   nC: number of clusters, should be <= n
  #
  # Returns:
  #   The estimated K centers from data X, variances, and contributions 
  
  # TODO: Shuffle the incoming data
  d = dim(X)[1] # dimension of data
  n = dim(X)[2] # number of observations
  # Init beta:
  beta = 1
  # init C, C idx is shifted by 1, C[[iter_t+1]] is C[[t]] 
  C <- list(nC)
  # Init alpha as 1/c(initial)
  alpha = rep(1/nC, nC)
  # Init mu with every observations in X
  # TODO: Take a random sample of data points as initial mu if nC < n (pag 4), if so check seed
  # idx_sample <- sample(1:n, nC)
  # mu_update <- lapply(idx_sample, function(k) { X[,k] })
  mu_update <- lapply(1:nC, function(k) { X[,k] })
  # Init outliers
  outliers <- c()
  
  ## Initialize Sigma
  
  # Calculating d_min^2 and Q
  d_m = .Machine$double.xmax
  for (i in 1:(n-1)) {
    for (j in (i+1):n) {
      dif <- norm(X[,i] - X[,j], "2")^2
      if (dif > 0 & dif < d_m) {
        d_m = dif
      }
    }
  }
  Q <- d_m * diag(d)
  
  # Calculating initial sigma
  Sigma <- list()
  g <- 0.0001
  for (k in 1:nC) {
    # Creating Sigma_k with eq (27)
    dist <- numeric(n)
    for (i in 1:n) {
      if (i != k) {
        dist[i] = norm(X[,i] - mu_update[[k]], "2")^2
      }
    }
    dist <- sort(dist)
    d_k_c_init = dist[ceiling(sqrt(nC))]
    
    # Creating sigma tilde: Use eq (28) to avoid issue with matrix being close to singular. 
    Sigma[[k]] <- (1-g)* d_k_c_init * diag(d) + g * Q
  }
  
  ## Initialize Z
  Z <- as.data.frame(matrix(0, n, nC))
  is_stable <- F
  for (j in 1:n) {
    for (k in 1:nC) {
      Z[j,k] = alpha[k]*dmvnorm(mu_update[[k]], Sigma[[k]], X[,j])
    }
    Z[j,] <- Z[j,]/sum(Z[j,])
  }
  
  # Compute first iteration of mu
  mu_update <- list()
  for (k in 1:C[[1]]) {
    mu_update[[k]] <- X %*% Z[,k]/sum(Z[,k])
  }
  mu <- mu_update
  
  # Loop:
  for (i in 1:m_iter) {
    print(paste("i:", i))
    print(paste("C:", C))
    print(paste("beta:", beta))
    
    # step 5: update of alpha
    a_em = colSums(Z)/n
    alpha_update = sapply(1:C[[i]], function(k, alpha, a_em) {
      a_em[k] + beta * alpha[k] * (log(alpha[k]) - t(alpha)%*%(log(alpha))) # where is beta?
    }, alpha, a_em)

    # step 6: update beta
    tmp1 <- (1-max(a_em))/(-max(alpha)*t(alpha)%*%log(alpha)) # error in log(alpha)
    eta <- min(1, 0.5^floor(d/2 - 1))
    tmp2 <- 0
    for (k in 1:C[[i]]) { # eq 24
      tmp2<-tmp2+exp(-eta*n*abs(alpha_update[k] - alpha[k]))/C[[i]]
    }
    # stop updating beta (perm beta = 0) when C is stable
    if (!is_stable) beta <- min(tmp1, tmp2)

    # step 7:
    # discard all clusters with contribution <= 1/n
    keep <- which(alpha_update > 1/n)
    alpha_update <- alpha_update[keep]
    # update mu (discard clusters)
    mu_update <- mu_update[keep]
    # update number of clusters
    C[[i+1]] <- length(alpha_update)
    # update alpha, eq (15)
    alpha <- alpha_update/sum(alpha_update)
    # update Z, eq (16)
    Z <- as.matrix(Z[,keep])
    for (j in 1:n) {
      Z[j,] <- Z[j,]/sum(Z[j,])
    }
    # check stability of C
    if (i >= 60) {
      if (C[[i-59]] == C[[i+1]]) {
        beta <- 0
        is_stable = T
      }
    }
    
    # Extra: Identify outliers, by checking what went to NA on the first coordinate
    outlier <- which(is.na(Z[,1]))
    if (length(outlier) > 0) {
      Z <- Z[-outlier,]
      outliers <- cbind(outliers, X[,outlier])
      X <- X[,-outlier]
      n <- n - length(outlier)
    }
    
    # TODO: check rest
    # update Sigma
    Sigma <- lapply(1:C[[i+1]], function(k, X, mu_update, Z, d, d_m) {
      gamma <- 0.0001
      # compute all X_i - Mu
      x_diff_mu <- sweep(X, MARGIN = 1, STATS = mu_update[[k]]) 
      # eq 26
      
      vcovs <- matrix(as.matrix(apply(x_diff_mu, 2, function(x) {
        x %*% t(x)
      }))%*%Z[,k], d, d)/sum(Z[,k])
      # eq 28
      (1 - gamma)*vcovs + gamma*d_m*diag(d)
    }, X, mu_update, Z,d,d_m)
    
    # update Z
    for (j in 1:n) {
      for (k in 1:C[[i+1]]) {
        Z[j,k] = alpha[k]*dmvnorm(mu_update[[k]], Sigma[[k]], X[,j])
      }
      Z[j,] <- Z[j,]/sum(Z[j,])
    }
    # update mu
    mu_update <- lapply(1:C[[i+1]], function(k, X, Z) {
      X %*% Z[,k]/sum(Z[,k])
    }, X, Z)
    
    dif <- as.matrix(sapply(mu_update, cbind) - sapply(mu[keep], cbind))
    m_dif <- max(apply(dif, 2, function(d) { norm(d, "2") }))
    if (m_dif < tol) {
      # check against tolerance
      OUT <- list(mu = mu_update, 
                  Sigma = Sigma, 
                  alpha = alpha,
                  iter = i,
                  outliers = outliers) 
      # return a named list of elements of interest
      return(OUT)
    }
    mu <- mu_update
  }
  # If failed to converge
  message(paste("failed to converge in", m_iter,"iterations."))
  OUT <- list(mu = mu_update, 
                  Sigma = Sigma, 
                  alpha = alpha,
                  iter = i,
                  outliers = outliers) 
      # return a named list of elements of interest
  return(OUT)
}
```

### Small testing module
```{r}
library(MASS)
set.seed(44)

alpha = c(1/2, 1/2)
mu_1 = c(0,0)
mu_2 = c(20,0)

S1 = matrix(c(1,0,0,1),2,2)
S2 = S1 * 9

X1 <- MASS::mvrnorm(n = 400, mu = mu_1, Sigma = S1)
X2 <- MASS::mvrnorm(n = 400, mu = mu_2, Sigma = S2)
X <- rbind(X1, X2)
random_shuffle <- sample(1:800, 800)
X <- X[random_shuffle,]
X <- t(X)

nC <- 30
tol <- 1e-10
m_iter <- 1e4
```

```{r}
system.time(EM_res <- EM_Robust(X, 800))
```

```{r}
library(shape)
draw_ellipse <- function(EM_res, i) {
  colour <- c("steelblue", "aquamarine", 
              "darkorchid", "brown1", 
              "deeppink3", "orange")
  center <- EM_res$mu[[i]]
  tmp <- sqrt(eigen(EM_res$Sigma[[i]])$values*qchisq(p=0.95, df = 2))

  lines(getellipse(rx = tmp[2], ry = tmp[1], mid = center), col = colour[i],
        lwd = 2)
  points(x = center[1], y = center[2], pch = 19, col = "red")
}
```

```{r}
plot(x = X[1,], y = X[2,],col = adjustcolor(col = "black" ,alpha.f = 0.5),
     pch = 19, ylim = c(-10,10))
# Ellipse
for (i in 1:2) {
  draw_ellipse(EM_res, i)
}
```

### Archive

```{r}
## 20 simulations
set.seed(5)
reg_ems <- list()
robust_ems <- list()
datasets <- list()
C = 3
n <- 3

for (i in 1:n){
  message(i)
  ## Generate a new dataset
  alpha = c(1/3, 1/3, 1/3)
  mu_1 = c(0,3)
  mu_2 = c(0,5)
  mu_3 = c(0,7)
  
  S1 = matrix(c(1.2,0,0,0.01),2,2)
  
  df <- 1.5
  X1 <- LaplacesDemon::rmvt(n = 100, mu = mu_1, S = S1, df = df)
  X2 <- LaplacesDemon::rmvt(n = 100, mu = mu_2, S = S1, df = df)
  X3 <- LaplacesDemon::rmvt(n = 100, mu = mu_3, S = S1, df = df)
    
  X <- rbind(X1, X2, X3)
  X <- t(X)
  datasets[[i]] <- X
  
  ## Run EM
  # print(paste0(format(Sys.time(),'%H:%M:%S'), " - EM ", i))
  # Z <- sample(1:C, 300, replace = T)
  # reg_ems[[i]] <- EM(X=X, C=C, Z=Z, tol=1e-10, m_iter=1e3)
  
  ## Run robust
  print(paste0(format(Sys.time(),'%H:%M:%S'), " - Robust ", i))
  robust_ems[[i]] <- EM_Robust(X, 300)
}
```
Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

